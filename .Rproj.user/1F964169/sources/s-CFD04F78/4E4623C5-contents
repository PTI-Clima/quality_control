# Author: Miguel Tomas Burguera <http://www.eead.csic.es/home/staffinfo?Id=459>; Erosion, and Soil and Water Evaluation , EEAD, CSIC <http://www.eead.csic.es>. Fergus Reig Gracia <http://fergusreig.es/>; Environmental Hydrology, Climate and Human Activity Interactions, Geoenvironmental Processes, IPE, CSIC <http://www.ipe.csic.es/hidrologia-ambiental/>
# Version: 1.0

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/> <http://www.gnu.org/licenses/gpl.txt/>.
#####################################################################

library(reshape)
library(reshape2)

##################################################################
#### FUNCION PARA LEER LOS DATOS DE LOS ARCHIVOS TXT DE AEMET ####
##################################################################

#' Elimina filas sin ningún valor distinto de NA y de -999
#'
#' @param data Matriz que se devolverá una vez eliminadas que no aportan información
#'
#' @return Matriz de datos
#' @export
#'
#' @examples
delete_na = function(data) {
  data.na = !is.na(data[-c(1:3)]) & data[-c(1:3)] != -999
  data.sum = apply(data.na, c(1), sumf, na.rm = TRUE)
  data.0 = data.sum > 0
  data = data[data.0,]
  return(data)
}

#' Elimina filas sin datos sobre su posición en la matriz de distancias
#'
#' @param data Matriz que se devolverá una vez eliminadas filas de las que no conocemos distancias a la estación
#' @param dist Matriz de distancias
#'
#' @return Matriz de datos
#' @export
#'
#' @examples
delete_no_dist = function(data, dist) {
  data.aux = as.character(data[, "INDICATIVO"]) %in% colnames(dist)
  if (sum(!data.aux) > 0) {
    warning(paste(
      length(unique(data[!data.aux, 1])),
      "estaciones con datos no aparecen en el fichero de estaciones"
    ))
  }
  data = data[data.aux,]
  return(data)
}

#' Elimina filas y columnas no compartidas entre las 2 matrices que recibe
#'
#' @param data1 Matriz que se devolverá una vez eliminadas filas y columnas no presentes en el segundo parámetro
#' @param data2 Matriz auxiliar con la que comparar filas y columnas
#'
#' @return Matriz de datos
#' @export
#'
#' @examples
compatibles_row_col = function(data1, data2) {
  data1 = data1[rownames(data1) %in% rownames(data2), colnames(data1) %in% colnames(data2)]
  return(data1)
}

#' Lee datos del SIAR desde los ficheros de origen y los devuelve
#'
#' @param a directorio en el que están los ficheros
#' @param var tipo de datos (tmin, pr...)
#'
#' @return Matriz de datos
#' @export
#'
#' @examples
lectura_datos_siar_var = function(a, var) {
  library(chron)
  col.name = toupper(var)
  file.name = var
  if (var == C_RA) {
    col.name = ""
    file.name = C_R
  } else{
    if (var == C_PP) {
      col.name = "P"
      file.name = C_PR
    }
  }

  if (is.na(a)) {
    a = "files_data"
  }

  files <-
    list.files(
      path = a,
      pattern = ".txt$|.csv$|.tmp$",
      full.names = TRUE,
      recursive = TRUE
    )
  files <- files[grepl(var, files)]
  files <- files[!grepl("coor", files)]
  files <- files[!grepl("Descripcion", files)]
  if(length(files)>0){
    ori.csv <- NULL
    f <- files[1]
    for (f in files) {
      ori.csv.aux <- read.csv(f, sep = ";")
      if(!C_MONTH%in%colnames(ori.csv.aux)){
        dates <- chron(rownames(ori.csv.aux), format = c(dates = "d/m/yy", times = "h:m:s"))
        ori.csv.aux <- cbind(as.character(chron::years(dates)), as.numeric(months(dates)), chron::days(dates), ori.csv.aux)
        colnames(ori.csv.aux)[1:3] <- c("year", C_MONTH, C_DAY)
      }
      if (!is.null(ori.csv)) {
        new.names <- colnames(ori.csv.aux)[!colnames(ori.csv.aux) %in% colnames(ori.csv)]
        ori.csv[, new.names] <- NA
        new.names <-
          colnames(ori.csv)[!colnames(ori.csv) %in% colnames(ori.csv.aux)]
        ori.csv.aux[, new.names] <- NA
        ori.csv <- rbind(ori.csv, ori.csv.aux)
      } else{
        ori.csv <- ori.csv.aux
      }
      rm(ori.csv.aux)
      gc()
    }      
    ori.csv = ori.csv[!duplicated(ori.csv[, c("year", C_MONTH, C_DAY)], fromLast =
                                    TRUE),]

    # http://seananderson.ca/2013/10/19/reshape.html
    t.csv <- reshape2::melt(ori.csv, id.vars = c("year", C_MONTH, C_DAY))
    t.csv <- cast(t.csv, variable + year + month ~ day, NULL)
    colnames(t.csv)[colnames(t.csv)=="variable"] = "INDICATIVO"
    colnames(t.csv)[colnames(t.csv)=="year"] = "AÑO"
    colnames(t.csv)[colnames(t.csv)=="month"] = "MES"
    colnames(t.csv)[4:dim(t.csv)[2]] = paste0(col.name, colnames(t.csv)[4:dim(t.csv)[2]])
    t.csv = t.csv[, c("INDICATIVO", "AÑO", "MES", paste0(col.name, 1:31))]

    if (var == C_TMIN | var == C_TMAX) {
      #Grados - grados/10
      t.csv[, -c(1:3)] = t.csv[, -c(1:3)] * 10
    } else{
      if (var == C_W) {
        #M/s a 2 metros - km/h a 10 metros # *3600/(0.75*1000)
        t.csv[, -c(1:3)] = 3600 * t.csv[, -c(1:3)] / 750
      } else{
        if (var == C_PP) {
          # var = C_PP # mm - mm/10
          t.csv[, -c(1:3)] = t.csv[, -c(1:3)] * 10
        } else{
          # var = C_RA # MJ/m2 - 10*KJ/m2
          if (var == C_RA) {
            t.csv[, -c(1:3)] = 100 * t.csv[, -c(1:3)]
          } else{
            if (var != C_HR) {
              # var = C_HR # %
              stop('Variable incorrecta')
            }
          }
        }
      }
    }
    # HR y W, ¿pruebas solo con datos diarios?
    t.csv$INDICATIVO = as.factor(t.csv$INDICATIVO)
    if (length(class(t.csv)) > 1) {
      class(t.csv) = class(t.csv)[2]
    }
    return(t.csv)
  }
  return(NA)
}

#' Lee datos del SIAR desde los ficheros de origen y los devuelve
#'
#' @param a directorio en el que están los ficheros
#' @param var tipo de datos (tmin, pr...)
#'
#' @return Matriz o lista de matrices de datos
#' @export
#'
#' @examples
lectura_datos_siar <- function(a, var) {
  if (var == C_T) {
    return(list(
      min = lectura_datos_siar_var(a = NA, var = C_TMIN),
      max = lectura_datos_siar_var(a = NA, var = C_TMAX)
    ))
  } else{
    return(lectura_datos_siar_var(a = NA, var = var))
  }
}

#' Lee datos del SIAR o AEMET desde los ficheros de origen y los devuelve
#'
#' @param a directorio en el que están los ficheros
#' @param var tipo de datos (tmin, pr...)
#' @param data_source fuente de los datos (AEMET o SIAR)
#'
#' @return Matriz o lista de matrices de datos
#' @export
#'
#' @examples
lectura_datos <- function(a, var, data_source = C_AEMET) {
  if (data_source == C_SIAR) {
    return(lectura_datos_siar(a, var))
  }else{
    return(lectura_datos_aemet(a, var))
  }
}

#' Lee datos del AEMET desde los ficheros de origen y los devuelve
#'
#' @param a directorio en el que están los ficheros
#' @param var tipo de datos (tmin, pr...)
#' @param data_source fuente de los datos (AEMET o SIAR)
#'
#' @return Matriz o lista de matrices de datos
#' @export
#'
#' @examples
lectura_datos_aemet <- function(a, var) {
  if (var != C_T &
      var != C_PP &
      var != C_HR & var != C_W & var != C_INS & var != C_RA & var != C_P) {
    stop('Variable incorrecta')
  }

  # Las columnas de datos con las que nos quedamos varían en función de la
  # variable que tratamos.
  if (var == C_T) {
    w <- c('INDICATIVO',
           'AÑO',
           'MES',
           paste('TMAX', c(1:31), sep = ''),
           paste('TMIN', c(1:31), sep = ''))
    var.name = "Termo"
  }
  if (var == C_PP) {
    w <- c('INDICATIVO', 'AÑO', 'MES', paste('P', c(1:31), sep = ''))
    var.name = "Pluvio"
  }
  if (var == C_HR) {
    w <- c('INDICATIVO',
           'AÑO',
           'MES',
           'DIA',
           'HU00',
           'HU07',
           'HU13',
           'HU18')
    var.name = "Humedad"
  }
  if (var == C_W) {
    w <-
      c('INDICATIVO',
        'AÑO',
        'MES',
        'DIA',
        'VEL_00',
        'VEL_07',
        'VEL_13',
        'VEL_18')
    var.name = "Viento"
  }
  if (var == C_INS) {
    w <- c('INDICATIVO', 'AÑO', 'MES', 'DIA', 'TOTSOL')
    var.name = "Insolacion"
  }
  if (var == C_RA) {
    w <- c('INDICATIVO', 'AÑO', 'MES', 'DIA', 'RGLODIA')
    var.name = "Radiacion"
  }
  if (var == C_P) {
    w <-
      c('INDICATIVO',
        'AÑO',
        'MES',
        'DIA',
        'PRES00',
        'PRES07',
        'PRES13',
        'PRES18')
    var.name = "Presion"
  }

  ## Obtenemos el listado de archivos de texto de la variable de interés
  files <-
    list.files(
      path = a,
      pattern = ".txt$|.csv$|.tmp$",
      full.names = TRUE,
      recursive = TRUE
    )
  files <- files[grepl(var.name, files)]
  files <- files[!grepl("Descripcion", files)]
  
  # files <- "C:\\Users\\mgil\\Downloads\\hum_relativa22_muestra.csv"

  DF <- NULL

  
  bind34 = function(datos) {
    if (dim(datos)[2] < 34) {
      datos = cbind(datos, rep(NA, dim(datos)[1]))
      colnames(datos)[dim(datos)[2]] = "31"
    }
    return(datos)
  }

  ## Leemos los datos de temperatura
  if (var == C_T) {
    for (f in files) {
      dat <- read.table(
        paste(f, sep = ""),
        sep = ";",
        header = T,
        encoding = 'latin1',
        quote = ''
      )[, w]
      dat = dat[!duplicated(dat[, c("INDICATIVO", "AÑO", "MES")], fromLast =
                              FALSE),]
      DF <- rbind(DF, dat)
      rm(dat)
      gc()
    }
    DF = DF[!duplicated(DF[, c("INDICATIVO", "AÑO", "MES")], fromLast =
                          TRUE),]

    ## Separamos los datos de Temperatura maxima de los de temperatura mínima
    DF_max <- DF[, c(1:34)]
    DF_min <- DF[, c(1:3, 35:65)]
    return(list(max = DF_max, min = DF_min))
  }

  ## Leemos los datos de precipitación
  if (var == C_PP) {
    for (f in files) {
      dat <- read.table(
        paste(f, sep = ""),
        sep = ";",
        header = T,
        encoding = 'latin1',
        quote = ''
      )[, w]
      dat = dat[!duplicated(dat[, c("INDICATIVO", "AÑO", "MES")], fromLast =
                              FALSE),]

      # Convertimos los -3 a 0
      dat[dat == -3] <- 0

      DF <- rbind(DF, dat)
      rm(dat)
      gc()
    }
    DF = DF[!duplicated(DF[, c("INDICATIVO", "AÑO", "MES")], fromLast = TRUE),]
    return(DF)
  }

  ## Leemos los datos de humedad, viento o presión
  if (var == C_HR | var == C_W | var == C_P) {
    for (f in files) {
      dat <- read.table(
        paste(f, sep = ""),
        sep = ";",
        header = T,
        encoding = 'latin1',
        quote = ''
      )[, w]

      if ("DIA" %in% colnames(dat)) {
        dat = dat[!duplicated(dat[, c("INDICATIVO", "AÑO", "MES", "DIA")], fromLast =
                                FALSE),]
      } else{
        dat = dat[!duplicated(dat[, c("INDICATIVO", "AÑO", "MES")], fromLast = FALSE),]
      }

      dat_0 <- dat[, c(1:5)]
      dat_1 <- dat[, c(1:4, 6)]
      dat_2 <- dat[, c(1:4, 7)]
      dat_3 <- dat[, c(1:4, 8)]

      dat_0 <- cast(dat_0, INDICATIVO + 'AÑO' + MES ~ DIA, value = colnames(dat_0)[5])
      dat_0 = bind34(dat_0)
      colnames(dat_0)[4:34] <- paste(var, '00_', c(1:31), sep = '')
      dat_1 <- cast(dat_1, INDICATIVO + 'AÑO' + MES ~ DIA, value = colnames(dat_1)[5])
      dat_1 = bind34(dat_1)
      colnames(dat_1)[4:34] <- paste(var, '07_', c(1:31), sep = '')
      dat_2 <- cast(dat_2, INDICATIVO + 'AÑO' + MES ~ DIA, value = colnames(dat_2)[5])
      dat_2 = bind34(dat_2)
      colnames(dat_2)[4:34] <- paste(var, '13_', c(1:31), sep = '')
      dat_3 <- cast(dat_3, INDICATIVO + 'AÑO' + MES ~ DIA, value = colnames(dat_3)[5])
      dat_3 = bind34(dat_3)
      colnames(dat_3)[4:34] <- paste(var, '18_', c(1:31), sep = '')

      # Lo juntamos todo en una misma matriz
      dat <- cbind(dat_0, dat_1[, 4:34], dat_2[, 4:34], dat_3[, 4:34])

      #
      DF <- rbind(DF, dat)
      rm(dat)
      gc()
    }
    if (var == C_HR | var == C_W) {
      a <- grep(paste('^', var, '00', sep = ''), colnames(DF))
      b <- grep(paste('^', var, '07', sep = ''), colnames(DF))
      c <- grep(paste('^', var, '13', sep = ''), colnames(DF))
      d <- grep(paste('^', var, '18', sep = ''), colnames(DF))
      orden <- c(1, 2, 3)
      for (i in 1:31) {
        orden <- c(orden, a[i], b[i], c[i], d[i])
      }
    }
    DF <- DF[, orden]
    if ("DIA" %in% colnames(DF)) {
      DF = DF[!duplicated(DF[, c("INDICATIVO", "AÑO", "MES", "DIA")], fromLast =
                            TRUE),]
    } else{
      DF = DF[!duplicated(DF[, c("INDICATIVO", "AÑO", "MES")], fromLast = TRUE),]
    }
    return(DF)
  }

  ## Leemos los datos de insolacion
  if (var == C_INS | var == C_RA) {
    for (f in files) {
      dat <-
        read.table(
          paste(f, sep = ""),
          sep = ";",
          header = T,
          encoding = 'latin1',
          quote = ''
        )[, w]

      dat = dat[!duplicated(dat[, c("INDICATIVO", "AÑO", "MES", "DIA")], fromLast =
                              FALSE),]

      dat <-
        cast(dat, INDICATIVO + 'AÑO' + MES ~ DIA, value = colnames(dat)[5])
      dat = bind34(dat)
      DF <- rbind(DF, dat)
      rm(dat)
      gc()
    }
    DF = DF[!duplicated(DF[, c("INDICATIVO", "AÑO", "MES")], fromLast =
                          TRUE),]
    class(DF) = "data.frame"
    return(DF)
  }

}

#' Lee archivos de distancias y homogeneiza las coordenadas
#'
#' @return matrizde datos
#' @export
#'
#' @examples
ficheroDistanciasLeer = function() {
  crs28 = "+proj=utm +zone=28 +ellps=intl +units=m +no_defs"

  dist1 = read.csv("files_data/28c.txt", sep = ";")[, c(1:5)]
  dist2 = read.csv("files_data/30c.txt", sep = ";")[, c(1:5)]

  est_sp1 <- dist1
  coordinates(est_sp1) <- c('UTM.X', 'UTM.Y')
  proj4string(est_sp1) <- crs28
  est_sp1 <- spTransform(est_sp1, CRS(crs30))
  dist1[, c("UTM.X", "UTM.Y")] = est_sp1@coords
  dist = rbind(dist1, dist2)
  dist = dist[dist[, "Base"] == C_SIAR,]
  dist = cbind(dist, array(NA, dim = c(dim(dist)[1], 3)))
  dist = dist[c(1, 6, 7, 2, 3, 4, 5, 8)]
  colnames(dist) = c(
    'INDICATIVO',
    'NOMBRE',
    'ALTITUD',
    'C_X',
    'C_Y',
    'NOM_PROV',
    'LONGITUD',
    'LATITUD'
  )
  dist["NOM_PROV"] = NA
  dist["LONGITUD"] = NA

  est_sp <- dist
  coordinates(est_sp) <- c('C_X', 'C_Y')
  proj4string(est_sp) <- crs30
  est_sp = spTransform(est_sp, CRS(crslonlat))
  dist[, c("LONGITUD", "LATITUD")] = est_sp@coords

  return(dist)
}

#' Crea archivo de distancias
#'
#' @param a directorio en el que están los ficheros
#' @param var tipo de datos (tmin, pr...)
#' @param data_source fuente de los datos (AEMET o SIAR)
#'
#' @return data frame de datos
#' @export
#'
#' @examples
distancias <- function(a, var, data_source = C_AEMET) {
  if (data_source == C_SIAR) {
    DF = ficheroDistanciasLeer()
  } else{
    if (var != C_T &
        var != C_PP &
        var != C_HR & var != C_W & var != C_INS & var != C_RA & var != C_P) {
      stop('Variable incorrecta')
    }

    if (var == C_T) {
      var.name = "Termo"
    }
    if (var == C_PP) {
      var.name = "Pluvio"
    }
    if (var == C_HR) {
      var.name = "Humedad"
    }
    if (var == C_W) {
      var.name = "Viento"
    }
    if (var == C_INS) {
      var.name = "Insolacion"
    }
    if (var == C_RA) {
      var.name = "Radiacion"
    }
    if (var == C_P) {
      var.name = "Presion"
    }

    # Las columnas de datos con las que nos quedamos

    w <-
      c(
        'INDICATIVO',
        'NOMBRE',
        'ALTITUD',
        'C_X',
        'C_Y',
        'NOM_PROV',
        'LONGITUD',
        'LATITUD'
      )

    files <-
      list.files(
        path = a,
        pattern = ".txt$|.csv$|.tmp$",
        full.names = TRUE,
        recursive = TRUE
      )
    files <- files[grepl(var.name, files)]
    files <- files[!grepl("Descripcion", files)]
    
    # files <- "C:\\Users\\mgil\\Downloads\\hum_relativa22_muestra.csv"

    DF <- NULL

    ## Leemos los datos
    f <- files[1]
    for (f in files) {
      dat <- read.table(
        paste(f, sep = ""),
        sep = ";",
        header = T,
        encoding = 'latin1',
        quote = ''
      )[, w]

      dat[,"LONGITUD"] = as.factor(dat[,"LONGITUD"])
      dat[,"LATITUD"] = as.factor(dat[,"LATITUD"])
      DF <- rbind(DF, dat)
      rm(dat)
      gc()
    }
    DF <- unique(DF)
    DF = DF[!duplicated(DF[, "INDICATIVO"], fromLast = TRUE),]
  }
  coords <- DF
  save.data(coords, file = paste('coords_', var, '.RData', sep = ''))

  d <- DF[, c('C_X', 'C_Y')]
  distancia <- dist(d)
  distancia <- as.data.frame(as.matrix(distancia))
  rownames(distancia) <- colnames(distancia) <- DF$INDICATIVO
  distancia$INDICATIVO <- DF$INDICATIVO

  return(distancia)
}

#' creamos metadatos originales para temperatura
#'
#' @param datos matriz de datos
#'
#' @return Matriz de datos
#' @export
#'
#' @examples
crear_metadatos_originales <- function(datos) {
  metadatos_originales <- datos
  metadatos_originales[, 4:ncol(datos)] <-
    metadatos_originales[, 4:ncol(datos)] - metadatos_originales[, 4:ncol(datos)]
  return(metadatos_originales)
}

###############################################
#### DETECCION Y TRATAMIENTO DE DUPLICADOS ####
###############################################

#' deteccion de meses duplicados
#'
#' @param datos matriz de datos
#' @param metadatos matriz de metadatos correspondientes a los datos
#' @param dist matriz de distancias
#' @param var tipo de datos (tmin, pr...)
#' @param pasada La pr distingue entre la pasada 1 y la 2 a la hora de guardar algunos datos
#' @param data_source Distinguir si tratamos datos de la AEMET o del SIAR
#'
#' @return None
#' @export
#'
meses_duplicados <-
  function(datos,
           metadatos,
           dist,
           var,
           pasada = 1,
           data_source = C_AEMET) {
    dupl <-
      deteccion_duplicados(datos, metadatos, var, data_source = data_source)

    metadatos_meses_duplicados_detectados <- dupl$metadatos
    duplicados <- dupl$duplicados

    if (var == C_PP & pasada == 2) {
      ## duplicados es una lista que contiene 4 elementos. Los duplicados a 28, 29, 30 y 31 dias
      ## metadatos_meses_duplicados_detectados vale '1' en duplicados, '0' en originales, 'NA' en no disponibles
      save.data(
        duplicados,
        file = paste(
          'Duplicados/Meses/Paso 1/Duplicados_a_dias_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
      save.data(
        metadatos_meses_duplicados_detectados,
        file = paste(
          'Duplicados/Meses/Paso 1/metadatos_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else {
      ## duplicados es una lista que contiene 4 elementos. Los duplicados a 28, 29, 30 y 31 dias
      ## metadatos_meses_duplicados_detectados vale '1' en duplicados, '0' en originales, 'NA' en no disponibles
      save.data(
        duplicados,
        file = paste(
          'Duplicados/Meses/Paso 1/Duplicados_a_dias_',
          var,
          '.RData',
          sep = ''
        )
      )
      save.data(
        metadatos_meses_duplicados_detectados,
        file = paste('Duplicados/Meses/Paso 1/metadatos_', var, '.RData', sep =
                       '')
      )
    }

    ## despues de esta funcion, metadatos_meses_duplicados_lista es una lista de 4 posiciones (28,29,30 y 31 días) que tiene valores:
    ## '2' (eliminar), '3' (conservar), '4' (conservar por cercanía espacial)
    ## eliminar contiene las filas de los elementos que se tienen que eliminar
    dat <-
      tratamiento_duplicados(datos,
                             duplicados,
                             metadatos_meses_duplicados_detectados,
                             dist,
                             var,
                             data_source = data_source)

    metadatos_meses_duplicados_lista <- dat$metadatos
    eliminar <- dat$eliminar

    if (var == C_PP & pasada == 2) {
      save.data(
        metadatos_meses_duplicados_lista,
        file = paste(
          'Duplicados/Meses/Paso 2/metadatos_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else{
      save.data(
        metadatos_meses_duplicados_lista,
        file = paste('Duplicados/Meses/Paso 2/metadatos_', var, '.RData', sep =
                       '')
      )
    }

    ## construimos un objeto final: metadatos_meses_duplicados_final.
    ## vale '2' si se tiene que eliminar, '1' si se ha detectado pero no se tiene que eliminar, '0' si no ha saltado deteccion,
    ## 'NA' si no hay dato original.
    metadatos_meses_duplicados_final <-
      metadatos_meses_duplicados_detectados
    metadatos_meses_duplicados_final[eliminar, 4:ncol(datos)] <- 2

    if (var == C_PP & pasada == 2) {
      save.data(
        metadatos_meses_duplicados_final,
        file = paste(
          'Duplicados/Meses/Paso 3/metadatos_meses_duplicados_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else{
      save.data(
        metadatos_meses_duplicados_final,
        file = paste(
          'Duplicados/Meses/Paso 3/metadatos_meses_duplicados_',
          var,
          '.RData',
          sep = ''
        )
      )
    }
  }

#' deteccion de decenas climaticas duplicadas
#'
#' @param datos matriz de datos
#' @param metadatos matriz de metadatos correspondientes a los datos
#' @param var tipo de datos (tmin, pr...)
#' @param pasada La pr distingue entre la pasada 1 y la 2 a la hora de guardar algunos datos
#' @param data_source Distinguir si tratamos datos de la AEMET o del SIAR
#'
#' @return None
#' @export
#'
#' @examples
decenas_duplicadas <-
  function(datos,
           metadatos,
           var,
           pasada = 1,
           data_source = C_AEMET) {
    ## duplicados es una lista con 3 elementos. Cada elemento contiene los duplicados de cada decena climatica
    ## metadatos_decenas_duplicadas es un objeto de metadatos. '1' si se ha detectado decena duplicada, '0' si el dato es original,
    ## 'NA' si no hay dato original

    dec_duplicadas <- deteccion_decenas_duplicadas(data=datos, metadatos=metadatos, var=var, data_source = data_source)

    duplicados <- dec_duplicadas$dec_dupl
    metadatos_decenas_duplicadas <- dec_duplicadas$metadatos

    if (var == C_PP & pasada == 2) {
      save.data(
        duplicados,
        file = paste(
          'Duplicados/Decenas/Paso 1/dec_duplicados_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
      save.data(
        metadatos_decenas_duplicadas,
        file = paste(
          'Duplicados/Decenas/Paso 1/metadatos_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else{
      save.data(
        duplicados,
        file = paste(
          'Duplicados/Decenas/Paso 1/dec_duplicados_',
          var,
          '.RData',
          sep = ''
        )
      )
      save.data(
        metadatos_decenas_duplicadas,
        file = paste(
          'Duplicados/Decenas/Paso 1/metadatos_',
          var,
          '.RData',
          sep = ''
        )
      )
    }

    ## metadatos_decenas_duplicadas_final es un objeto de metadatos.
    ## '2' el mes tiene dos decenas duplicadas. Hay que eliminar el mes entero
    ## '5' el mes tiene una única decena duplicada. Hay que eliminar únicamente esa decena.
    metadatos_decenas_duplicadas_final <-
      tratar_decenas_duplicadas(duplicados, metadatos_decenas_duplicadas, var, data_source =
                                  data_source)

    if (var == C_PP & pasada == 2) {
      save.data(
        metadatos_decenas_duplicadas_final,
        file = paste(
          'Duplicados/Decenas/Paso 2/metadatos_decenas_duplicadas_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else{
      save.data(
        metadatos_decenas_duplicadas_final,
        file = paste(
          'Duplicados/Decenas/Paso 2/metadatos_decenas_duplicadas_',
          var,
          '.RData',
          sep = ''
        )
      )
    }
  }

#' deteccion de intradecenas duplicadas
#'
#' @param datos matriz de datos
#' @param metadatos matriz de metadatos correspondientes a los datos
#' @param var tipo de datos (tmin, pr...)
#' @param pasada La pr distingue entre la pasada 1 y la 2 a la hora de guardar algunos datos
#' @param data_source Distinguir si tratamos datos de la AEMET o del SIAR
#'
#' @return None
#' @export
#'
#' @examples
intradecenas_duplicadas <-
  function(datos,
           metadatos,
           var,
           pasada = 1,
           data_source = C_AEMET) {
    intra_dec_dupl <-
      intradecadal_duplicated(data=datos, meta=metadatos, var=var, data_source = data_source)

    ## metadatos vale '1' para los casos que estan duplicados, '0' para datos originales y 'NA'
    ## No hay necesidad de más tratamiento. Cualquier decena intraduplicada se eliminará
    metadatos_intradecenas_duplicadas <- intra_dec_dupl$meta

    if (var == C_PP & pasada == 2) {
      save.data(
        metadatos_intradecenas_duplicadas,
        file = paste(
          'Duplicados/Intradecenas/metadatos_intradecenas_',
          var,
          '_pasada2.RData',
          sep = ''
        )
      )
    } else {
      save.data(
        metadatos_intradecenas_duplicadas,
        file = paste(
          'Duplicados/Intradecenas/metadatos_intradecenas_',
          var,
          '.RData',
          sep = ''
        )
      )
    }
  }

#' deteccion de meses con 25 dias identicos
#'
#' @param datos matriz de datos
#' @param metadatos matriz de metadatos correspondientes a los datos
#' @param var tipo de datos (tmin, pr...)
#' @param dist matriz de distancias
#' @param data_source Distinguir si tratamos datos de la AEMET o del SIAR
#'
#' @return None
#' @export
#'
#' @examples
deteccion_duplicados_25_dias <-
  function(data, metadatos, var, dist, data_source = C_AEMET) {
    if (var == C_MIN |
        var == C_MAX | var == C_INS | var == C_RA | data_source == C_SIAR) {
      th_min <- 24
      th_max <- 31
    } else{
      if (var == C_HR | var == C_W) {
        th_min <- 84
        th_max <- 127
      }
    }
    dupl <- matrix(NA, nrow = 5000, ncol = 50)

    rownames(data) = 1:dim(data)[1]
    data.ori = data
    a <- !is.na(data[, 4:ncol(data)])
    col.a <- apply (a, 1, sum, na.rm = T)
    b <- col.b <- 0
    if (var == C_HR) {
      b <- data[, 4:ncol(data)] == 100
      col.b <- apply (b, 1, sum, na.rm = T)
    }
    if (var == C_W | var == C_INS) {
      b <- data[, 4:ncol(data)] == 0
      col.b <- apply (b, 1, sum, na.rm = T)
    }
    data = data[col.a > 24 & col.b < th_min,]

    rownames.calc = rownames(data)
    cpp.bin = file.path(dataOutFiles, paste(var, "bin", sep = "."))
    data = as.matrix(data[4:dim(data)[2]])
    ncol = dim(data)[2] + 1
    nrow = dim(data)[1]
    data[is.na(data)] = -999
    data <- cbind(data, rep(0, dim(data)[1]))
    data = c(t(data))
    data = as.integer(data)
    con <- file(cpp.bin, "wb")
    aux = writeBin(as.integer(nrow * ncol), con, size = 4)
    aux = writeBin(data, con, size = 2)
    close(con)

    eq = main_deteccion_duplicados(cpp.bin, th_min, th_max, ncol)
    eq = strsplit(eq, ";")[[1]]
    e = 1
    for (e in seqf(1, length(eq))) {
      equal = strsplit(eq[[e]], "=")[[1]]
      dupl[e, 1] = as.numeric(rownames.calc[1 + as.numeric(equal[1])])
      equal = strsplit(equal[2], ",")[[1]]
      if ((length(equal) + 1) > dim(dupl)[2]) {
        dupl = cbind(dupl, matrix(
          NA,
          nrow = 5000,
          ncol = length(equal) + 1 - dim(dupl)[2]
        ))
      }
      dupl[e, 2:(length(equal) + 1)] = as.numeric(rownames.calc[1 + as.numeric(equal)])
    }
    aux = file.remove(cpp.bin)

    data = data.ori
    w <- which(is.na(dupl[, 1]))
    dupl <- dupl[-w, ]

    duplicados <- list(NULL)
    if (length(dupl) > 50) {
      for (i in 1:dim(dupl)[1]) {
        duplicados[[i]] <- data[dupl[i, which(!is.na(dupl[i, ]))], ]
        metadatos[dupl[which(!is.na(dupl[i, ]))], 4:ncol(metadatos)] <-
          1
      }
    } else{
      duplicados[[1]] <- data[dupl[which(!is.na(dupl))], ]
      metadatos[dupl[which(!is.na(dupl))], 4:ncol(metadatos)] <- 1
    }
    duplicados_25 <- duplicados
    metadatos_duplicados_25 <- metadatos

    save.data(duplicados_25,
              file = paste('Duplicados/25_dias/duplicados_', var, '.RData', sep = ''))
    save.data(
      metadatos_duplicados_25,
      file = paste(
        'Duplicados/25_dias/metadatos_duplicados_',
        var,
        '.RData',
        sep = ''
      )
    )

    metadatos_duplicados_25_final <-
      tratamiento_unicos_25(
        x = data,
        s = duplicados_25,
        b = metadatos,
        d = dist        
      )
    save.data(
      metadatos_duplicados_25_final,
      file = paste(
        'Duplicados/25_dias/metadatos_duplicados_final_',
        var,
        '.RData',
        sep = ''
      )
    )
  }


#' Si hay más de 6 días con lluvia idéntica entre meses consecutivos se considera que el mes está duplicado
#'
#' @param data data frame de datos
#' @param metadata frame de metadatos correspondientes a los datos
#'
#' @return None
#' @export
#'
#' @examples
n_dias_duplicados <- function(data, meta) {
  dupl <- NULL
  stations <- as.character(unique(data$INDICATIVO))
  sta <- 1
  for (sta in 1:length(stations)) {
    # print(stations[sta])
    dat <- data[data$INDICATIVO == stations[sta], ]
    if (dim(dat)[1] > 1) {
      meses <- which(rowSums(dat[, 4:34] != 0) > 6)
      if (length(meses) > 1) {
        dat <- dat[meses, ]
        # suppressWarnings: la conversión de tipos que hace R funciona para el caso de uso
        suppressWarnings(dat[dat <= 0] <- NA)
        for (month in 1:(dim(dat)[1] - 1)) {
          r <- dat[month:dim(dat)[1], ]
          a <- as.numeric(r[1, 4:34])
          aa <- r[2:nrow(r), 4:34]
          comparison <-
            matrix(a,
                   nrow = nrow(r) - 1,
                   ncol = 31,
                   byrow = T) - aa
          identicos <- rowSums(comparison == 0, na.rm = T)
          w <- which(identicos > 5)
          if (length(w) > 0) {
            w <- w + 1
            datos_1 <- length(which(!is.na(r[1, 4:34])))
            if (length(w) == 1) {
              datos_2 <- length(which(!is.na(r[w, 4:34])))
              if (identicos[(w - 1)] * 2 >= datos_1 &
                  identicos[(w - 1)] * 2 >= datos_2) {
                rep <- c(stations[sta], sta, r[1, 2:3], r[w, 2:3])
                dupl <- rbind(dupl, rep)
                meta[meta$INDICATIVO == stations[sta] &
                       meta$YEAR == r[1, 'YEAR'] & meta$MES == r[1, 'MES'], 4:34] <- 2
                meta[meta$INDICATIVO == stations[sta] &
                       meta$YEAR == r[w, 'YEAR'] & meta$MES == r[w, 'MES'], 4:34] <- 2
              }
            } else {
              for (j in 1:length(w)) {
                datos_2 <- length(which(!is.na(r[w[j], 4:34])))
                if (identicos[(w[j] - 1)] * 2 >= datos_1 &
                    identicos[(w[j] - 1)] * 2 >= datos_2) {
                  rep <- c(stations[sta], sta, r[1, 2:3], r[w[j], 2:3])
                  dupl <- rbind(dupl, rep)
                  meta[meta$INDICATIVO == stations[sta] &
                         meta$YEAR == r[1, 'YEAR'] & meta$MES == r[1, 'MES'], 4:34] <- 2
                  meta[meta$INDICATIVO == stations[sta] &
                         meta$YEAR == r[w[j], 'YEAR'] & meta$MES == r[w[j], 'MES'], 4:34] <-
                    2
                }
              }
            }
          }
        }
      }
    }
  }
  dupl_2 <- list(NULL)
  if (!is.null(dim(dupl)[1])) {
    #CORREGIDO_MTOMAS
    for (i in 1:(dim(dupl)[1])) {
      dupl_2[[i]] <-
        data[data$INDICATIVO == dupl[i, 1] &
               ((data$YEAR == dupl[i, 3] & data$MES == dupl[i, 4]) |
                  (data$YEAR == dupl[i, 5] &
                     data$MES == dupl[i, 6])), ]
    }
  }
  dupl <- dupl_2
  metadatos_6_dias_duplicados <- meta
  save.data(dupl, file = 'Duplicados/6_dias/duplicados_a_6_dias.RData')
  save.data(metadatos_6_dias_duplicados, file = 'Duplicados/6_dias/metadatos_6_dias_duplicados.RData')
}

#' busca meses con las mismas cantidades de lluvia, aunque no esten en el mismo orden
#'
#' @param data matriz de datos
#' @param meta matriz de metadatos correspodientes a los datos de la matriz
#' @param pasada distinguimos entre la primera y segunda pasada para guardar algunos datos
#'
#' @return None
#' @export
#'
#' @examples
offset_duplicated_rain <- function(data,
                                   meta,
                                   pasada) {

  nz = 2
  ac = 50

  a <- data[, 1:3]
  b <- data[, 4:ncol(data)]

  ## Quitamos los -3
  b[b == -3] <- NA

  ## Quitamos los 0's
  b[b == 0] <- NA

  b <- t(apply(
    b,
    1,
    FUN = function(z) {
      w <- which(is.na(z))
      if (length(w) > 0) {
        z <- c(z[-w], z[w])
      }
      return(z)
    }
  ))

  data_2 <- cbind(a, b)
  ## Una vez le?dos los datos hay que hacer control de duplicados.
  w <- duplicated(data_2[, 4:34])
  ww <- duplicated(data_2[, 4:34], fromLast = TRUE)

  zeros <- rowSums(data_2[, 4:34] != 0, na.rm = T)
  acumulado <- rowSums(data_2[, 4:34], na.rm = T)
  litros <- rowSums(data_2[, 4:34] > 10, na.rm = T)

  duplicados <-
    which(litros > 4 & zeros > 3 & (w == T | ww == T) & acumulado > 50)
  dupl <- data_2[duplicados, ]

  dupl_lluvia <- agrupar_duplicados_offset(data, dupl)

  if (length(dupl_lluvia) > 0) {
    ## offset duplicados es de eliminacion directa. Por eso se tienen que eliminar los casos que han saltado por este control pero
    ## habian saltado previamente en el control de meses duplicados
    if (pasada == 1) {
      load.data(file = 'Duplicados/Meses/Paso 1/Duplicados_a_dias_pp.RData')
    } else {
      load.data(file = 'Duplicados/Meses/Paso 1/Duplicados_a_dias_pp_pasada2.RData')
    }

    dupl_lluvia <- lapply(
      dupl_lluvia,
      FUN = function(z) {
        colnames(z)[4:34] <- paste('P', 1:31, sep = '')
        return(z)
      }
    )

    c <-
      which(
        dupl_lluvia %in% duplicados[[1]] |
          dupl_lluvia %in% duplicados[[2]] |
          dupl_lluvia %in% duplicados[[3]] |
          dupl_lluvia %in% duplicados[[4]]
      )
    if (length(c) > 0) {
      dupl_lluvia <- dupl_lluvia[-c]
    }

    if (length(dupl_lluvia) > 0) {
      w <- NULL
      for (i in 1:length(dupl_lluvia)) {
        if (length(unique(dupl_lluvia[[i]][, 1])) == 1 |
            length(unique(dupl_lluvia[[i]][, 2])) == 1 |
            length(unique(dupl_lluvia[[i]][, 3])) == 1) {
          w <- c(w, i)
        }
      }
      dupl_lluvia <- dupl_lluvia[w]

      for (i in 1:length(dupl_lluvia)) {
        y <- dupl_lluvia[[i]]
        for (j in 1:dim(y)[1]) {
          meta[meta$INDICATIVO == y[j, 'INDICATIVO'] &
                 meta$YEAR == y[j, 'YEAR'] & meta$MES == y[j, 'MES'], 4:34] <- 2
        }
      }
    }
  }

  metadatos_offset <- meta
  if (pasada == 2) {
    save.data(dupl_lluvia, file = 'Duplicados/Offset/duplicados_con_offset_pasada2.RData')
    save.data(metadatos_offset, file = 'Duplicados/Offset/metadatos_offset_pasada2.RData')
  } else {
    save.data(dupl_lluvia, file = 'Duplicados/Offset/duplicados_con_offset.RData')
    save.data(metadatos_offset, file = 'Duplicados/Offset/metadatos_offset.RData')
  }
}

######################################
#### AGRUPAR METADATOS DUPLICADOS ####
######################################

#' reorganiza metadatos generados durante la ejecución
#'
#' @param metadatos matriz de metadatos
#' @param var tipo de dato (tmin, pr...)
#' @param pasada distinguimos entre la primera y segunda pasada para guardar algunos datos
#'
#' @return None
#' @export
#'
#' @examples
agrupar_metadatos_duplicados <- function(metadatos, var, pasada = 1) {
  if (var == C_PP) {
    if (pasada == 2) {
      load.data(file = 'Duplicados/metadatos_duplicados_combinados_pp.RData')

      load.data(file = 'Duplicados/Meses/Paso 3/metadatos_meses_duplicados_pp_pasada2.RData')
      metadatos_duplicados_combinados[metadatos_meses_duplicados_final ==
                                        2] <- 2

      load.data(file = 'Duplicados/Decenas/Paso 2/metadatos_decenas_duplicadas_pp_pasada2.RData')
      metadatos_duplicados_combinados[metadatos_decenas_duplicadas_final ==
                                        2 | metadatos_decenas_duplicadas_final == 5] <- 2

      load.data(file = 'Duplicados/Intradecenas/metadatos_intradecenas_pp_pasada2.RData')
      metadatos_duplicados_combinados[metadatos_intradecenas_duplicadas ==
                                        2] <- 2

      load.data(file = 'Duplicados/6_dias/metadatos_6_dias_duplicados.RData')
      metadatos_duplicados_combinados[metadatos_6_dias_duplicados == 2] <-
        2

      load.data(file = 'metadatos_menos_4_eliminados.RData')
      metadatos_duplicados_combinados[metadatos_menos_4 == 1] <-
        (-4)
      metadatos_duplicados_combinados[, 1:3] <-
        metadatos_menos_4[, 1:3]

      save.data(
        metadatos_duplicados_combinados,
        file = paste(
          'Duplicados/metadatos_duplicados_combinados_pp_pasada2.RData',
          sep = ''
        )
      )

    } else {
      ## como los metadatos de los meses duplicados son los primeros que se modifican, partimos de esta base
      load.data(file = 'Duplicados/Meses/Paso 3/metadatos_meses_duplicados_pp.RData')

      metadatos <- metadatos_meses_duplicados_final
      rm(metadatos_meses_duplicados_final)

      load.data(file = 'Duplicados/Decenas/Paso 2/metadatos_decenas_duplicadas_pp.RData')
      metadatos[metadatos_decenas_duplicadas_final == 2 |
                  metadatos_decenas_duplicadas_final == 5] <- 2

      load.data(file = 'Duplicados/Intradecenas/metadatos_intradecenas_pp.RData')
      metadatos[metadatos_intradecenas_duplicadas == 2] <- 2

      load.data(file = 'Duplicados/Offset/metadatos_offset.RData')
      metadatos[metadatos_offset == 2] <- 2
    }

  } else {
    ## como los metadatos de los meses duplicados son los primeros que se modifican, partimos de esta base
    load.data(
      file = paste(
        'Duplicados/Meses/Paso 3/metadatos_meses_duplicados_',
        var,
        '.RData',
        sep = ''
      )
    )

    metadatos <- metadatos_meses_duplicados_final
    rm(metadatos_meses_duplicados_final)

    ## combinamos con los metadatos de decenas duplicadas
    load.data(
      file = paste(
        'Duplicados/Decenas/Paso 2/metadatos_decenas_duplicadas_',
        var,
        '.RData',
        sep = ''
      )
    )
    w <- which(metadatos_decenas_duplicadas_final == 2, arr.ind = T)
    w <- w[-c(which(w[, 2] < 4)), ]
    w <- unique(w[, 1])
    if (length(w) > 0) {
      for (i in 1:length(w)) {
        ww <- which(!is.na(metadatos[w[i], ]))
        ww <- ww[-c(1:3)]
        metadatos[w[i], ww] <- 2
      }
    }

    w <- which(metadatos_decenas_duplicadas_final == 5, arr.ind = T)
    w <- w[-c(which(w[, 2] < 4)), ]
    if (length(w) > 0) {
      for (i in 1:dim(w)[1]) {
        metadatos[w[i, 1], w[i, 2]] <- 2
      }
    }
    rm(metadatos_decenas_duplicadas_final)

    ## combinamos con los metadatos de intradecenas duplicadas
    load.data(
      file = paste(
        'Duplicados/Intradecenas/metadatos_intradecenas_',
        var,
        '.RData',
        sep = ''
      )
    )
    w <- which(metadatos_intradecenas_duplicadas == 2, arr.ind = T)
    w <- w[-c(which(w[, 2] < 4)), ]
    if (length(w) > 0) {
      for (i in 1:dim(w)[1]) {
        metadatos[w[i, 1], w[i, 2]] <- 2
      }
    }
    rm(metadatos_intradecenas_duplicadas)

    ## combinamos con los metadatos de 25 dias duplicados
    load.data(
      file = paste(
        'Duplicados/25_dias/metadatos_duplicados_final_',
        var,
        '.RData',
        sep = ''
      )
    )

    w <- which(metadatos_duplicados_25_final == 2, arr.ind = T)
    w <- w[-c(which(w[, 2] < 4)), ]
    w <- unique(w[, 1])
    if (length(w) > 0) {
      metadatos[w, 4:34] <- 2
    }

    w <- which(metadatos_duplicados_25_final == 5, arr.ind = T)
    w <- w[-c(which(w[, 2] < 4)), ]
    if (length(w) > 0) {
      for (i in 1:dim(w)[1]) {
        metadatos[w[i, 1], w[i, 2]] <- 2
      }
    }
  }
  metadatos_duplicados_combinados <- metadatos
  save.data(
    metadatos_duplicados_combinados,
    file = paste(
      'Duplicados/metadatos_duplicados_combinados_',
      var,
      '.RData',
      sep = ''
    )
  )
}

#############################
#### REFORMATEAMOS DATOS ####
#############################

#' reformateamos datos a formato ancho
#'
#' @param datos matriz de datos
#'
#' @return data frame de de los datos con el nuevo formato
#' @export
#'
#' @examples
reformat <- function(datos) {
  library(chron)
  library(Hmisc) #CORREGIDO_MTOMAS
  d.colnames = c("YEAR", "MES", "DIA", unique(as.character(datos[, "INDICATIVO"])))
  datos[, "MES"] = as.character(datos[, "MES"])
  dates = apply(datos[, c("MES", "YEAR")], c(1), paste, collapse = " ")
  dates = chron(gsub(" ", "/1/", dates),
                out.format = c(dates = "yy/m/d", times = "h:m:s"))
  maxDayMonth = monthDays(base::as.Date(paste(
    chron::years(max(dates)), as.integer(months(max(dates))), '01', sep = "-"
  ))) #CORREGIDO_MTOMAS
  dates = seq.dates(min(dates), chron(
    paste(as.integer(months(max(
      dates
    ))), maxDayMonth, chron::years(max(dates)), sep = "/"),
    format = c(dates = "m/d/y", times = "h:m:s")
  ))
  d = array(NA, dim = c(length(dates), length(d.colnames)))
  colnames(d) = d.colnames
  d[, "YEAR"] = as.integer(as.character(chron::years(dates)))
  d[, "MES"] = as.integer(months(dates))
  d[, "DIA"] = as.integer(chron::days(dates))
  rownames(d) = paste(d[, "DIA"], d[, "MES"], d[, "YEAR"], sep = "/")

  ## reformateamos los datos  #CORREGIDO_MTOMAS, no cabe en memoria
  colnames(datos)[4:34] <- as.integer(1:31)
  a <- reshape2::melt(datos, id.vars = c('INDICATIVO', 'YEAR', 'MES'))
  colnames(a)[4] <- 'DIA'
  class(a[, "value"])<- "numeric"

  years = unique(a[, "YEAR"])
  years = years[order(years)]
  y = years[1]
  for (y in years) {
    a.y = a[which(a[, "YEAR"] == y), ]
    b <- dcast(a.y, YEAR + MES + DIA ~ INDICATIVO, value.var="value", fun.aggregate=mean)

    rownames(b) = paste(b[, "DIA"], b[, "MES"], b[, "YEAR"], sep = "/")
    rows.b = rownames(b)[rownames(b) %in% rownames(d)]
    d[rows.b, colnames(b)] = as.numeric(as.matrix(b[rows.b, colnames(b)]))
  }
  b <- as.data.frame(d)
  return(b)
}

#' pasa de datos subdiarios a datos diarios
#'
#' @param dat07 matriz de datos a las 7
#' @param dat13 matriz de datos a las 13
#' @param dat18 matriz de datos a las 18
#'
#' @return matriz de datos diarios
#' @export
#'
#' @examples
from_subdaily_to_daily <- function(dat07, dat13, dat18) {
  daily_data <- dat07
  daily_data <- (dat07 + dat13 + dat18) / 3
  return(daily_data)
}

#######################################################
#### DETECCION Y ELIMINACION DE DATOS CONSECUTIVOS ####
#######################################################

#' deteccion de datos consecutivos
#'
#' @param data matriz de datos
#' @param metadatos matriz de metadatos
#' @param var tipo de datos (tmin, pr...)
#' @param vart Hora del día de los datos (no para todos los var)
#'
#' @return matriz de metadatos o none
#' @export
#'
#' @examples
detectar_consecutivos <- function(datos, metadatos, var, vart = NULL) {
  if (var == C_MAX | var == C_MIN) {
    resolucion_datos <- datos
    resolucion_datos[, 4:ncol(datos)] <-
      datos[, 4:ncol(datos)] - datos[, 4:ncol(datos)]

    resolucion_datos <- obtener_resolucion(datos, resolucion_datos)
    save.data(
      resolucion_datos,
      file = paste(
        'Consecutivos/Paso 1/Resolucion_datos_',
        var,
        '.RData',
        sep = ''
      )
    )

    metadatos_consecutivos_7 <- consecutivos(datos, metadatos, C = 7)
    metadatos_consecutivos_14 <- consecutivos(datos, metadatos, C = 14)

    metadatos_consecutivos <-
      combinar_metadatos_consecutivos(metadatos_consecutivos_7,
                                      metadatos_consecutivos_14,
                                      resolucion_datos)
    save.data(
      metadatos_consecutivos,
      file = paste('Consecutivos/Paso 1/Consecutivos_', var, '.RData', sep = '')
    )
  }
  if (var == C_W) {
    metadatos_consecutivos <- consecutivos(datos, metadatos, C = 7)
    save.data(
      metadatos_consecutivos,
      file = paste(
        'Consecutivos/Paso 1/Consecutivos_',
        var,
        '_',
        vart,
        '.RData',
        sep = ''
      )
    )
    return(metadatos_consecutivos)
  }
  if (var == C_INS) {
    metadatos_consecutivos_7 <- consecutivos(datos, metadatos, C = 7)
    metadatos_consecutivos_20 <- consecutivos(datos, metadatos, C = 20)
    metadatos_consecutivos_7 <-
      comprobar_consecutivos_insolacion(datos, metadatos_consecutivos_7)

    metadatos_consecutivos <-
      combinar_metadatos_consecutivos(metadatos_consecutivos_7,
                                      metadatos_consecutivos_20,
                                      var = C_INS)

    save.data(
      metadatos_consecutivos,
      file = paste('Consecutivos/Paso 1/Consecutivos_', var, '.RData', sep = '')
    )
  }
  if (var == C_RA) {
    metadatos_consecutivos <- consecutivos(datos, metadatos, C = 3)
    metadatos_consecutivos[metadatos_consecutivos == 1] <- 13
    metadatos_consecutivos[, 1:3] <- datos[, 1:3]
    save.data(
      metadatos_consecutivos,
      file = paste('Consecutivos/Paso 1/Consecutivos_', var, '.RData', sep = '')
    )
  }
  if (var == C_HR) {
    metadatos_consecutivos_7 <- consecutivos(datos, metadatos, C = 7)
    metadatos_consecutivos_20 <- consecutivos(datos, metadatos, C = 20)

    metadatos_consecutivos <-
      combinar_metadatos_consecutivos(metadatos_consecutivos_7,
                                      metadatos_consecutivos_20,
                                      datos,
                                      var = C_HR)
    save.data(
      metadatos_consecutivos,
      file = paste(
        'Consecutivos/Paso 1/Consecutivos_',
        var,
        '_',
        vart,
        '.RData',
        sep = ''
      )
    )
    return(metadatos_consecutivos)
  }
  if (var == C_PP) {
    metadatos_consecutivos <- metadatos
    ## Se permiten 6 días de lluvia idéntica inferior a 1mm
    ## Se permiten 4 días de lluvia idéntica inferior a 10mm
    ## Se permiten 2 días de lluvia idéntica inferior a 50mm
    ## No se permiten dias consecutivos con lluvia idéntica por encima de 50mm
    metadatos_dias <- consecutivos(datos, metadatos, 7) == 1
    metadatos_consecutivos[metadatos_dias &
                             datos < 10 & datos > 0] <- 13
    metadatos_dias <- consecutivos(datos, metadatos, 5) == 1
    metadatos_consecutivos[metadatos_dias &
                             datos < 100 & datos > 9] <- 13
    metadatos_dias <- consecutivos(datos, metadatos, 3) == 1
    metadatos_consecutivos[metadatos_dias &
                             datos < 500 & datos > 99] <- 13
    metadatos_dias <- consecutivos(datos, metadatos, 2) == 1
    metadatos_consecutivos[metadatos_dias & datos > 499] <- 13

    ## Detectamos los casos con 3 dias consecutivos por encima de 100mm
    ## Detectamos los casos con 5 dias consecutivos por encima de 50mm
    datos.pre = datos[, c(1:3)] #CORREGIDO_MTOMAS
    datos[datos > 500 & datos < 1000] <- 500
    datos[datos > 999] <- 1000
    datos[, c(1:3)] = datos.pre #CORREGIDO_MTOMAS
    metadatos_dias <- consecutivos(datos, metadatos, 5) == 1
    metadatos_consecutivos[metadatos_dias & datos > 499] <- 15
    metadatos_dias <- consecutivos(datos, metadatos, 3) == 1
    metadatos_consecutivos[metadatos_dias & datos > 999] <- 15
    metadatos_consecutivos[, 1:3] <- datos[, 1:3]
    save.data(
      metadatos_consecutivos,
      file = paste('Consecutivos/Paso 1/Consecutivos_pp.RData', sep = '')
    )
  }
}

#' Busca datos de hr con poca variabilidad
#'
#' @param x_07 matriz de datos a las 7 horas
#' @param x_13 matriz de datos a las 13 horas
#' @param x_18 matriz de datos a las 18 horas
#' @param C Tamaño de la ventana móvil
#' @param E variabilidad 
#' @param G si los datos máximos deben estar por debajo o por encima de 95
#'
#' @return Matriz de metadatos
#' @export
#'
#' @examples
poca_variacion_bucle <- function(x_07,
                                 x_13,
                                 x_18,
                                 C = 10,
                                 E = 5,
                                 G = T) {
  critA <- matrix(NA, nrow = (nrow(x_07) * 3 - (C - 1)), ncol = ncol(x_07) -
                    3)

  for (i in 4:ncol(x_07)) {
    print(i)
    ## preparamos los datos
    dat_1 <- x_07[, c(1, 2, 3, i)]
    dat_2 <- x_13[, c(1, 2, 3, i)]
    dat_3 <- x_18[, c(1, 2, 3, i)]
    a <- rbind(dat_1, dat_2, dat_3)
    a <- a[c(order(a$YEAR, a$MES, a$DIA)), ]

    ## preparamos la matriz
    critA[, (i - 3)] <- apply(
      embed(a[, 4], (C)),
      1,
      FUN = function(k)
        (((max(
          k
        ) - min(
          k
        )) < E) & ((
          max(k, na.rm = T) - min(k, na.rm = T)
        ) > 0) &
          (G | max(k, na.rm = T) < 95) & (!G | max(k, na.rm = T) > 95))
    )
  }

  critA <-
    rbind(critA, matrix(rep(FALSE, (ncol(
      x_07
    ) - 3) * (C - 1)), (C - 1)))
  b <- critA
  w <- which(critA, arr.ind = T)
  if (dim(w)[1] > 0) {
    ww <- w[, 1] + (C - 1)
    for (i in 1:length(ww)) {
      b[w[i, 1]:ww[i], w[i, 2]] <- 15
    }
  }

  cc <- matrix(NA, nrow = nrow(x_07), ncol = ncol(x_07))

  for (i in 1:nrow(cc)) {
    cc[i, 4:ncol(cc)] <- b[3 * i - 2, ]
  }
  cc <- as.data.frame(cc)
  cc[, 1:3] <- x_07[, 1:3]
  colnames(cc) <- colnames(x_07)
  rownames(cc) <- rownames(x_07)
  return(cc)
}

#################################################
#### DETECCION Y ELIMINACION DE FALSOS CEROS ####
#################################################

#' Busca falsos 0's
#'
#' @param datos Matriz de datos
#' @param metadatos Matriz de metadatos
#' @param var tipo de datos (pr, tmin...)
#'
#' @return None
#' @export
#'
#' @examples
zeros_aislados <- function(datos, metadatos, var) {
  for (i in 4:ncol(datos)) {
    w <- which(datos[, i] == 0)
    if (length(w) > 0) {
      for (j in 1:length(w)) {
        dat <- datos[c(which(datos$YEAR == datos$YEAR[w[j]] &
                               datos$MES == datos$MES[w[j]])), i]
        dat2 <- dat[-c(which(dat == 0))]
        ww <- which(!is.na(dat2))
        if (length(ww) > 0) {
          dat2 <- min(dat2, na.rm = T)
          if (dat2 > 100) {
            metadatos[w[j], i] <- 11
          }
        }
      }
    }
  }
  metadatos_zeros <- metadatos
  save.data(metadatos_zeros,
            file = paste('Zeros/Paso 1/Zeros_aislados_', var, '.RData', sep = ''))
}

#' 0's que estan tanto en las minimas como en las maximas
#'
#' @param dat1 Matriz de tmin o tmax
#' @param dat2 Matriz de tmin o tmax
#'
#' @return None
#' @export
#'
#' @examples
#' dat1=min; dat2=max
zeros_dobles <- function(dat1, dat2) {
  dat1 = compatibles_row_col(dat1, dat2)
  dat2 = compatibles_row_col(dat2, dat1)

  w <- which(dat1 == 0 & dat2 == 0, arr.ind = T)
  load.data(file = paste('Zeros/Paso 1/Zeros_aislados_min.RData', sep =
                           ''))
  if (length(w) > 0) {
    #CORREGIDO_MTOMAS
    for (i in 1:dim(w)[1]) {
      metadatos_zeros[rownames(dat1)[w[i, 1]], colnames(dat1)[w[i, 2]]] <-
        12
    }
  }
  save.data(metadatos_zeros, file = 'Zeros/Paso 2/Zeros_comunes_min.RData')

  load.data(file = paste('Zeros/Paso 1/Zeros_aislados_max.RData', sep =
                           ''))
  if (length(w) > 0) {
    #CORREGIDO_MTOMAS
    for (i in 1:dim(w)[1]) {
      metadatos_zeros[rownames(dat1)[w[i, 1]], colnames(dat1)[w[i, 2]]] <-
        12
    }
  }
  save.data(metadatos_zeros, file = 'Zeros/Paso 2/Zeros_comunes_max.RData')
}

##########################################################
#### DETECCION Y ELIMINACION DE MESES MAL CODIFICADOS ####
##########################################################

#' Detecta mala codificación en las temperaturas
#'
#' @param datos matriz de datos
#' @param metadatos matriz de metadatos
#' @param var tipo de datos (tmin, pr...) 
#'
#' @return matriz de metadatos o none
#' @export
#'
#' @examples
mala_codificacion_temperatura <-
  function(datos, metadatos, var) {
    th_range = 25
    limited <- T
    for (i in 4:ncol(datos)) {
      th_range_mod <- th_range
      if (length(grep('^C', colnames(datos)[i])) > 0) {
        th_range_mod <- 15
      }
      a <-
        aggregate(
          datos[, i],
          by = list(datos$YEAR, datos$MES),
          FUN = function(zz) {
            rr <- F
            if (sum(!is.na(zz)) > 15) {
              if ((var == C_MAX & max(zz, na.rm = T) < 40) |
                  (var == C_MIN &
                   max(zz, na.rm = T) < 40 & min(zz, na.rm = T) > -40)) {
                rr <- max(zz, na.rm = T) - min(zz, na.rm = T)
                if (rr == -Inf) {
                  rr <- F
                } else {
                  rr <- rr < 30
                }
              }
            }
            return(rr)
          }
        )
      w <- which(a$x == T)
      if (length(w > 0)) {
        for (k in 1:length(w)) {
          metadatos[c(which(
            metadatos$YEAR == a$Group.1[w[k]] &
              metadatos$MES == a$Group.2[w[k]]
          )), i] <- 14
        }
      }
      a <-
        aggregate(
          datos[, i],
          by = list(datos$YEAR, datos$MES),
          FUN = function(zz) {
            rr <- F
            if (sum(!is.na(zz)) > 15) {
              rr <- max(zz, na.rm = T) - min(zz, na.rm = T)
              if (rr == -Inf) {
                rr <- F
              } else {
                rr <- rr < th_range_mod
              }
            }
            return(rr)
          }
        )
      w <- which(a$x == T)
      if (length(w > 0)) {
        for (k in 1:length(w)) {
          if (is.na(metadatos[c(which(
            metadatos$YEAR == a$Group.1[w[k]] &
            metadatos$MES == a$Group.2[w[k]]
          )), i][1]) |
          metadatos[c(which(
            metadatos$YEAR == a$Group.1[w[k]] &
            metadatos$MES == a$Group.2[w[k]]
          )), i][1] != 14) {
            metadatos[c(which(
              metadatos$YEAR == a$Group.1[w[k]] &
                metadatos$MES == a$Group.2[w[k]]
            )), i] <- 15
          }
        }
      }
    }
    metadatos_mala_codificacion <- metadatos
    save.data(
      metadatos_mala_codificacion,
      file = paste('Mala_codificacion/Mala_codificacion_', var, '.RData', sep =
                     '')
    )
  }


####################################################
#### DETECCION Y ELIMINACION DE DIAS ABERRANTES ####
####################################################

#' Marca en los metadatos los días con fechas aberrantes
#'
#' @param data matriz de datos
#' @param metadatos matriz de metadatos
#' @param var tipo de datos (tmin, pr...)
#' @param vart Hora del día de los datos (no para todos los var)
#'
#' @return Matriz de metadatos
#' @export
#'
#' @examples
deteccion_aberrantes <- function(data, metadatos, var, vart = NULL) {
  if (var == C_MAX | var == C_MIN) {
    metadatos_aberrantes <- metadatos
    rm(metadatos)

    data$DIA <- as.numeric(as.character(data$DIA))
    metadatos_aberrantes[data > 500] <- 21
    metadatos_aberrantes[data < (-350)] <- 22

    metadatos_aberrantes[, 1:3] <- data[, 1:3]
    save.data(
      metadatos_aberrantes,
      file = paste(
        'Aberrantes/Paso 1/metadatos_aberrantes_',
        var,
        '.RData',
        sep = ''
      )
    )
  }
  if (var == C_W) {
    load.data(file = 'Consecutivos/Paso 1/Consecutivos_w.RData')
    metadatos_aberrantes <- metadatos_consecutivos_U10
    rm(metadatos_consecutivos_U10)

    data$DIA <- as.numeric(as.character(data$DIA))

    metadatos_aberrantes[data > 220] <- 21
    metadatos_aberrantes[data < 0] <- 22
    metadatos_aberrantes[, 1:3] <- data[, 1:3]
    save.data(
      metadatos_aberrantes,
      file = paste(
        'Aberrantes/Paso 1/metadatos_aberrantes_',
        var,
        '_',
        vart,
        '.RData',
        sep = ''
      )
    )
    return(metadatos_aberrantes)
  }
  if (var == C_HR) {
    metadatos_aberrantes <- metadatos
    rm(metadatos)

    data$DIA <- as.numeric(as.character(data$DIA))

    metadatos_aberrantes[data > 100] <- 21
    metadatos_aberrantes[data < 0] <- 22
    metadatos_aberrantes[, 1:3] <- data[, 1:3]
    save.data(
      metadatos_aberrantes,
      file = paste(
        'Aberrantes/Paso 1/metadatos_aberrantes_',
        var,
        '_',
        vart,
        '.RData',
        sep = ''
      )
    )
    return(metadatos_aberrantes)
  }

  if (var == C_INS | var == C_RA) {
    metadatos_aberrantes <- metadatos
    rm(metadatos)

    data$DIA <- as.numeric(as.character(data$DIA))

    metadatos_aberrantes[data < 0] <- 22

    ## Hay dias por encima del maximo teorico?
    ## marcamos como límite 1.2
    load.data(paste('coords_', var, '.RData', sep = ''))
    DF <- NULL
    for (i in 4:ncol(data)) {
      LAT <-
        as.numeric(as.character(coords[c(which(coords$INDICATIVO == colnames(data)[i])), 'LATITUD']))
      if (LAT > 10000) {
        LAT <- round(LAT / 10000)
      }
      if (LAT > 1000 & LAT < 10000) {
        LAT <- round(LAT / 100)
      }
      fecha <- data[, 1:3]
      dato  <- data[, i] / 100
      mes   <- fecha$MES
      dias <- fecha$DIA

      max <- maximo_teorico(mes, LAT, var, dias)
      if (var == C_INS) {
        nN <- dato / max
        if (length(which(nN > 1.2)) > 0) {
          metadatos_aberrantes[which(nN > 1.2), i] <- 21
        }
      }
      if (var == C_RA) {
        dato <- dato
        nN <- dato / max
        if (length(which(nN > 0.97)) > 0) {
          metadatos_aberrantes[which(nN > 0.97), i] <- 21
        }
        if (length(which(nN < 0.01)) > 0) {
          metadatos_aberrantes[which(nN < 0.01), i] <- 22
        }
      }

    }

    metadatos_aberrantes[, 1:3] <- data[, 1:3]
    save.data(
      metadatos_aberrantes,
      file = paste('Aberrantes/metadatos_aberrantes_', var, '.RData', sep = '')
    )
    return(metadatos_aberrantes)
  }

}

#' Anota en los metadatos si la tmin es mayor o igual que la tmax
#'
#' @param data_min Matriz de datos de tmin
#' @param data_max Matriz de datos de tmax
#' @param metadatos_min Matriz de metadatos de tmin
#' @param metadatos_max Matriz de metadatos de tmax
#'
#' @return None
#' @export
#'
#' @examples
min_sup_eq_max <-
  function(data_min,
           data_max,
           metadatos_min,
           metadatos_max) {
    data_min = compatibles_row_col(data_min, data_max)
    data_max = compatibles_row_col(data_max, data_min)
    metadatos_min = compatibles_row_col(metadatos_min, metadatos_max)
    metadatos_max = compatibles_row_col(metadatos_max, metadatos_min)

    data_min$DIA <- as.numeric(as.character(data_min$DIA))
    data_max$DIA <- as.numeric(as.character(data_max$DIA))

    metadatos_min[data_min > data_max] <- 23
    metadatos_max[data_min > data_max] <- 23

    metadatos_min[data_min == data_max] <- 24
    metadatos_max[data_min == data_max] <- 24

    metadatos_min[, 1:3] <- data_min[, 1:3]
    metadatos_max[, 1:3] <- data_max[, 1:3]

    save.data(metadatos_min, file = 'Aberrantes/Paso 2/metadatos_min.RData')
    save.data(metadatos_max, file = 'Aberrantes/Paso 2/metadatos_max.RData')
  }

#' Guarda en los metadatos los días en los que el rango de temperatura supera un límite
#'
#' @param data_min Matriz de datos de tmin
#' @param data_max Matriz de datos de tmax
#' @param metadatos_min Matriz de metadatos de tmin
#' @param metadatos_max Matriz de metadatos de tmax
#' @param th_dr Diferencia permitida entre tmin y tmax
#'
#' @return None
#' @export
#'
#' @examples
daily_range <-
  function(data_min,
           data_max,
           metadatos_min,
           metadatos_max,
           th_dr = 350) {
    data_min = compatibles_row_col(data_min, data_max)
    data_max = compatibles_row_col(data_max, data_min)
    metadatos_min = compatibles_row_col(metadatos_min, metadatos_max)
    metadatos_max = compatibles_row_col(metadatos_max, metadatos_min)

    data_min$DIA <- as.numeric(as.character(data_min$DIA))
    data_max$DIA <- as.numeric(as.character(data_max$DIA))

    metadatos_min[data_max > (data_min + th_dr)] <- 25
    metadatos_max[data_max > (data_min + th_dr)] <- 25

    metadatos_min[, 1:3] <- data_min[, 1:3]
    metadatos_max[, 1:3] <- data_max[, 1:3]

    save.data(metadatos_min, file = 'Aberrantes/Paso 3/metadatos_dr_350_min.RData')
    save.data(metadatos_max, file = 'Aberrantes/Paso 3/metadatos_dr_350_max.RData')
  }

#' Pone NAs en la matriz de datos si así lo indican los valores de los metadatos
#'
#' @param data matriz de datos
#' @param metadata matriz de metadatos de los datos
#'
#' @return matriz de datos
#' @export
#'
eliminar_datos <- function(data, metadata) {
  data = compatibles_row_col(data, metadata)
  metadata = compatibles_row_col(metadata, data)

  data[metadata == 2 |
         metadata == 5 |
         metadata == 11 | metadata == 12 | metadata == 13 | metadata == 14 |
         metadata == 15 |
         metadata == 16 |
         metadata == 21 | metadata == 22 | metadata == 23 | metadata == 24 |
         metadata == 25 | metadata == 26 | metadata == 27] <- NA
  data[, 1:3] <- metadata[, 1:3]
  return(data)
}

##########################################
#### DETECCION DE ANOMALOS Y OUTLIERS ####
##########################################

########################################
#' Si hay mas de 'b' dias de 100% despues (o justo antes) de una cadena de 'a' nas consideramos error el 100 como valor erroneo
#'
#' @param data Matriz de datos
#' @param metadatos metadatos de los datos
#' @param A Longitud mínima de la cadena de NAs
#' @param B Longitud mínima de la cadena de 100's
#'
#' @return Metadatos de los datos
#' @export
#'
#' @examples
cien_entre_nas <- function(data,
                           metadatos,
                           A = 8,
                           B = 6) {
  for (j in 4:ncol(data)) {
    a <- data[, j]
    a[is.na(a)] <- (-10)
    xx <- rle(a)
    ww <- which(xx$values == (-10) & xx$length > A)
    for (i in seqf(1, length(ww))) {
      if (ww[i] > 1 & ww[i] < length(xx$value)) {
        if (xx$values[(ww[i] + 1)] == 100 & xx$length[(ww[i] + 1)] > B) {
          ## ubicamos la cadena de 100
          ini <- sum(xx$length[1:ww[i]]) + 1
          fin <- ini + xx$length[ww[i] + 1] - 1
          metadatos[ini:fin, j] <- 16
        }
        if (xx$values[(ww[i] - 1)] == 100 & xx$length[(ww[i] - 1)] > B) {
          ini <- sum(xx$length[1:(ww[i] - 2)]) + 1
          fin <- ini + xx$length[ww[i] - 1] - 1
          metadatos[ini:fin, j] <- 16
        }
      }
    }
  }
  return(metadatos)
}

#' Control específico para el numero de horas de sol. Se busca el maximo de horas
#' de sol dentro de una ventana móbil. Útil para detectar anomalías relacionadas
#' con la codificación. Hay casos en las series de AEMET en los que existen
#' codificaciones erróneas (aparentemente divididas por 10 respecto a su valor
#' observado.
#'
#' @param a matriz de datos
#' @param b metadatos de los datos
#' @param C Tamaño de la ventana móvil (parece mal usado, ya que se usa directamente su valor por defecto en algunos sitios)
#' @param D Parámetro para los cálculos, máximo de horas de insolación
#'
#' @return Metadatos de los datos
#' @export
#'
#' @examples
max_mobil  <- function(a, b, C = 15, D = 20) {
  critA <- apply(
    a,
    2,
    FUN = function(z)
      apply(
        embed(z, C),
        1,
        FUN = function(zz) {
          sum(!is.na(zz)) > 15 & max(zz, na.rm = T) < D
        }
      )
  )

  critA <- rbind(critA, matrix(rep(FALSE, ncol(a) * (C - 1)), (C - 1)))
  w <- which(critA, arr.ind = T)

  if (dim(w)[1] > 0) {
    ww <- w[, 1] + (C - 1)
    for (i in 1:length(ww)) {
      b[w[i, 1]:ww[i], w[i, 2]] <- 15
    }
  }
  b[, 1:3] <- a[, 1:3]
  metadatos_consecutivos <- b
  save.data(metadatos_consecutivos, file = 'Consecutivos/Paso 2/Consecutivos_ins.RData')
  return(b)
}

#' Function to delete -4 from the database previous to any other control
#' TS (TIME-SCALE).
#' TS=='D' (DAILY) ALL -4 and the acumulated rainfall is deleted
#' TS=='M' (MONTHLY) ALL -4 are deleted but the acumulated monthly data is preserved
#'
#' @param data Array de datos
#' @param bucle True para usar bucle en otro caso usar apply, elbucle ahorra RAM y el apply tiempo
#' @param TS D si queremos eliminar todos los -4
#'
#' @return Lista con los datos y los matedatos
#' @export
#'
#' @examples
special_character <- function(data, bucle = T, TS = 'D') {
  meta <- data
  meta_2 <- meta[, 4:34]
  meta_2[!is.na(meta_2)] <- 0
  meta[, 4:34] <- meta_2
  rm(meta_2)

  ac <- which(data == -4, arr.ind = T)
  meses <- unique(ac[, 1])

  ## HAY -4 A FINAL DE MES. SELECCIONAMOS LOS MESES SIGUIENTES Y ELIMINAMOS LA PRECIPITACION DEL DIA 1
  ## 1º buscamos -4 los dias 31
  final_mes_31 <- which(data[, 34] == -4)
  final_mes_31_mas_1 <- final_mes_31 + 1

  if (length(final_mes_31) > 0) {
    for (i in 1:length(final_mes_31)) {
      w <- which(data[final_mes_31[i], ] == -4)
      meta[final_mes_31[i], w] <- 1
      data[final_mes_31[i], w] <- NA
    }
  }

  ## buscamos -4 los dias 30 de final de mes
  final_mes_30 <-
    which(data[, 33] == -4 &
            (data$MES == 4 | data$MES == 6 | data$MES == 9 | data$MES == 11))
  final_mes_30_mas_1 <- final_mes_30 + 1

  ## buscamos -4 los dias 29 de final de mes
  final_mes_29 <- which(data[, 32] == -4 & data$MES == 2)
  final_mes_29_mas_1 <- final_mes_29 + 1

  ## buscamos -4 los dias 28 de final de mes
  final_mes_28 <-
    which(data[, 31] == -4 & is.na(data[, 32]) & data$MES == 2)
  final_mes_28_mas_1 <- final_mes_28 + 1

  final_mes_mas_1 <-
    c(final_mes_31_mas_1,
      final_mes_30_mas_1,
      final_mes_29_mas_1,
      final_mes_28_mas_1)
  data[final_mes_mas_1, 4] <- NA
  meta[final_mes_mas_1, 4] <- 1

  if (length(final_mes_31) > 0) {
    meses <- meses[-c(which(meses %in% final_mes_31))]
  }
  dat <- data[meses, ]
  met <- meta[meses, ]

  if (TS == 'D' & length(ac) > 0) {
    if (bucle == T) {
      for (i in 1:length(meses)) {
        w <- which(dat[i, ] == -4)
        met[i, w] <- 1
        met[i, (w + 1)] <- 1
        dat[i, w] <- NA
        dat[i, (w + 1)] <- NA
      }
      data[meses, ] <- dat
      meta[meses, ] <- met
    } else {
      data[ac, ] <- apply(
        data[ac],
        1,
        FUN = function(z) {
          w <- which(z == -4)
          z[w] <- NA
          z[(w + 1)] <- NA
          return(z)
        }
      )
    }
  }

  return(list(data = data, meta = meta))
}
